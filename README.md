# Pravaah Hackathon â€“ Causal Analysis over Conversational Data
## System Architecture
Raw Conversation JSON
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing â”‚ (preprocess.py)
â”‚ - Parse JSON â”‚
â”‚ - Clean text â”‚
â”‚ - Turn extraction â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature Engineering â”‚ (feature_engineering.py)
â”‚ - Sentiment â”‚
â”‚ - Speaker patterns â”‚
â”‚ - Escalation signals â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Causal Analysis (Task 1) â”‚ (causal_analysis.py)
â”‚ - Rule-based reasoning â”‚
â”‚ - Evidence identificationâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context-Aware Query Engine â”‚ (Task 2)
â”‚ - Context Manager â”‚
â”‚ - Multi-turn queries â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
Causal Explanations with Evidence

This project builds a system to analyze multi-turn conversational transcripts
and generate causally grounded explanations for outcome events such as
escalation, complaint, or refund.


## Setup and Installation

### Environment Setup (Recommended)

We recommend using a virtual environment to avoid dependency conflicts.

Using Conda:

```bash
conda create -n pravaah python=3.10
conda activate pravaah

### Install Dependencies
pip install -r requirements.txt
python -m textblob.download_corpora


## Project Structure
pravaah_hackathon/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ Conversational_Transcript_Dataset.json
â”‚ â”‚
â”‚ â””â”€â”€ processed/
â”‚ â”œâ”€â”€ conversations.csv
â”‚ â””â”€â”€ conversations_features.csv
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”œâ”€â”€ feature_engineering.py
â”‚ â”œâ”€â”€ causal_analysis.py
â”‚ â”œâ”€â”€ context_manager.py
â”‚ â””â”€â”€ query_engine.py
â”‚
â”œâ”€â”€ queries/
â”‚ â””â”€â”€ queries.csv
â”‚
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ task1_outputs.json
â”‚ â””â”€â”€ task2_outputs.json
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


---

## ğŸ“ Folder Description

```md
### Folder Description

- **data/**  
  Contains the raw conversational dataset and processed intermediate files.

- **src/**  
  Source code implementing preprocessing, feature engineering, causal analysis,
  and multi-turn context-aware query handling.

- **queries/**  
  Contains example analytical queries used to evaluate the system, including
  multi-turn dependent queries for Task 2.

- **outputs/**  
  Stores saved outputs generated by the system for:
  - Task 1: Causal explanation with evidence
  - Task 2: Multi-turn context-aware query responses

- **README.md**  
  Project documentation explaining the approach, design decisions, and usage.

- **requirements.txt**  
  Python dependencies required to reproduce the environment.


## Project Structure

data/        â€“ raw and processed datasets  
src/         â€“ source code  
README.md    â€“ project documentation  
requirements.txt â€“ environment dependencies  

## Step 1 Completed
- JSON preprocessing
- Turn-level conversation extraction
- Clean CSV generation

### Run preprocessing
```bash
python src/preprocess.py


## Step 2: Feature Engineering

### Purpose
The objective of this step is to convert raw conversational turns into
**structured, interpretable features** that reflect speaker behavior,
interaction patterns, and emotional signals.  
These features act as the foundation for downstream causal reasoning.

### Input
- `data/processed/conversations.csv`  
  (Generated after JSON preprocessing in Step 1)

### Output
- `data/processed/conversations_features.csv`

### Engineered Features

Each dialogue turn is enriched with the following attributes:

- **is_customer**  
  Identifies whether the turn is spoken by the customer or the agent.

- **sentiment**  
  A polarity score derived using TextBlob to capture emotional tone.

- **text_length**  
  Length of the utterance, used as a proxy for complaint severity.

- **contains_escalation_words**  
  Flags explicit escalation or complaint-related language.

These features preserve interpretability while enabling rule-based causal analysis.

### Execution

```bash
python src/feature_engineering.py

out put -- STEP 2 DONE: Features added. Rows = 84465



---

## âœ… **STEP 3: CAUSAL ANALYSIS AND EXPLANATION (TASK 1)**

```md
## Step 3: Causal Analysis and Explanation (Task 1)

### Purpose
This step focuses on answering **why** a particular outcome (such as
escalation or unresolved interaction) occurred, rather than predicting
whether it will occur.

The system produces **causally grounded explanations** supported by
explicit dialogue evidence.

### Input
- `data/processed/conversations_features.csv`

### Core Idea
Instead of using black-box models, the system applies
**deterministic causal rules** over conversational features to identify
root causes of interaction outcomes.

### Causal Heuristics Applied

The explanation engine considers multiple interaction-level factors:

- **Customer-dominated conversations**  
  Higher customer effort suggests unresolved concerns.

- **Conversation-level sentiment trend**  
  Sustained neutral-to-negative tone indicates dissatisfaction.

- **Extended interaction length**  
  Longer conversations act as a proxy for friction or failure to resolve issues.

- **Fallback causal rule**  
  Guarantees every conversation yields a grounded explanation without hallucination.

### Output Format

```json
{
  "conversation_id": "6794-8660-4606-3216",
  "causal_factors": [
    "Customer dominated the interaction indicating unresolved concern",
    "Extended interaction length indicating possible issue resolution difficulty"
  ],
  "evidence": [
    {
      "turn_id": 0,
      "speaker": "customer",
      "text": "i need help with my service"
    }
  ]
}

excuation -- python src/causal_analysis.py


## Step 4: Multi-Turn Context-Aware Query Handling (Task 2)

### Objective
Enable the system to support **multi-turn analytical interaction** where
follow-up queries depend on prior system responses, while maintaining
contextual consistency.

### Design Overview
This step introduces a lightweight memory mechanism that:
- Remembers the last referenced conversation
- Stores the causal explanation generated earlier
- Allows follow-up questions without repeating the conversation ID

The implementation is deterministic, interpretable, and evidence-based.

### Components

- **context_manager.py**  
  Maintains conversational state across multiple user queries.

- **query_engine.py**  
  Processes user queries and resolves them using stored context when applicable.

### Example Interaction

**Query 1 (Initial):**

**System Response:**
- Identifies causal factors
- Returns supporting dialogue turns as evidence

**Query 2 (Follow-up):**

**System Behavior:**
- Reuses the previously stored explanation
- Does not require the conversation ID again
- Returns consistent causal factors and evidence

### Sample Output

```json
{
  "conversation_id": "6794-8660-4606-3216",
  "causal_factors": [
    "Overall negative conversational tone over multiple turns",
    "Extended interaction length indicating possible issue resolution difficulty"
  ],
  "evidence": [
    {
      "turn_id": 1,
      "speaker": "Customer",
      "text": "hello im calling about an order that shows delivered but i never received it"
    }
  ]
}

## Evaluation (Qualitative)

Since the objective of this system is **causal explanation** rather than
prediction, we perform a qualitative evaluation instead of numerical metrics.

### Evaluation Criteria
The explanations are evaluated based on:
- **Faithfulness**: Are causal factors grounded in the actual conversation?
- **Evidence Traceability**: Can each explanation be traced to specific dialogue turns?
- **Consistency**: Does the system produce stable explanations for the same input?

### Observations
- Conversations with repeated customer frustration consistently yield
  explanations involving negative sentiment and extended interaction length.
- Explicit escalation language (e.g., â€œrefundâ€, â€œcomplaintâ€) is correctly
  identified and reflected in causal factors.
- Neutral or resolved conversations produce weak or fallback explanations,
  which is expected behavior.

Overall, the system generates **coherent, interpretable, and reproducible**
causal explanations aligned with human intuition.


## System Architecture

